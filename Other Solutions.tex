\section{Other Solutions/Current Literature}

\subsection{User Driven Solutions}
One of the most circuitous solutions to this is to track users' flagging accuracy to better maximize the efficiency of flags \citep{tschiatschek2018fake}. This is fundamentally flawed, as it assumes that any flaws in the process are the fault of the user flagging, not the third party reviewer, which is historically inaccurate. Furthermore, given how nebulous the definition for "fake" is -- and how inconsistent it is across platforms -- a user may flag something as being fake and be correct on one platform but not on another. For example, in order to consider a post worthy of removal, Facebook says the "misinformation and unverifiable rumors [must] contribute to the risk of imminent violence or physical harm" \citep{facebook2020violence}. Since the idea of "imminent violence or physical harm" is not \textit{a priori} contained in the concept of misinformation, it is reasonable that a user would flag something as being false and worthy of being removed, yet a facebook moderator might disagree. Indeed, the vague idea of "imminent violence" is similarly unsatisfying, as Welch drove to Washington D.C. almost four months after the first "pizzagate" conspiracy posts. By that logic, one could argue that while they were the direct cause of violence, the violence was not "immediate". This semantic debate about the idea of immediacy was, in fact, the defense used by Alex Jones of Infowars when he apologized for his support for "pizzagate" when threatened with a lawsuit, as he spoke at length that he was not the first person to propose or support this conspiracy, the attack happened after he had begun his media coverage, and that he had little do with the dissemination of the story at all \citep{rosenberg2017alex}. 

\subsection{}